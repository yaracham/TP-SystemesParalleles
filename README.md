# Travaux Pratiques ‚Äì Syst√®mes Parall√®les

Ce d√©p√¥t GitHub contient les **sujets des TP1 et TP2** ainsi que **mon rendu pour le TP2**, r√©alis√©s dans le cadre du cours de Syst√®mes Parall√®les.

## Organisation du d√©p√¥t

Le d√©p√¥t est structur√© de la mani√®re suivante :


### TP1
Le dossier **TP1** contient le sujet du TP1 ainsi que mon travail **√† partir de la partie 2 uniquement**, conform√©ment aux consignes.

Les exercices portent notamment sur :
- la parall√©lisation de calculs (OpenMP / MPI),
- la circulation de messages entre processus,
- des probl√©matiques classiques de calcul distribu√©.

### TP2
Le dossier **TP2** contient :
- le sujet complet du TP2,
- mon impl√©mentation et mon rendu,
- un mini-rapport pr√©sentant les **r√©sultats exp√©rimentaux** et leur **analyse**.

Le TP2 est structur√© autour de trois parties principales :
1. **Parall√©lisation de l‚Äôensemble de Mandelbrot**
2. **Produit matrice‚Äìvecteur**
3. **Entra√Ænement pour l‚Äôexamen √©crit (lois d‚ÄôAmdahl et de Gustafson)**

## R√©sultats principaux du TP2

### 1. Ensemble de Mandelbrot (MPI ‚Äì 4 processus, image 1024√ó1024)

| M√©thode                    | Temps d‚Äôex√©cution (s) |
|---------------------------|------------------------|
| R√©partition par blocs     | 1.061                  |
| R√©partition cyclique      | 1.051                  |
| Strat√©gie ma√Ætre-esclave  | 1.376                  |

**Analyse :**
- La r√©partition cyclique est l√©g√®rement plus performante gr√¢ce √† un meilleur √©quilibrage de charge.
- La r√©partition par blocs donne des performances proches, le d√©s√©quilibre restant limit√©.
- La strat√©gie ma√Ætre-esclave est p√©nalis√©e par le surco√ªt des communications MPI lorsque les t√¢ches sont fines.

üëâ Pour cette configuration, une **r√©partition statique bien choisie** est plus efficace qu‚Äôune strat√©gie dynamique.

### 2. Produit matrice‚Äìvecteur (MPI, np = 4)

Temps mesur√©s :
- D√©coupage par colonnes : `Tcols = 0.027088 s`
- D√©coupage par lignes : `Trows = 0.012808 s`

Le d√©coupage par lignes est environ **2.1√ó plus rapide** que le d√©coupage par colonnes, principalement √† cause du co√ªt des communications collectives (Allreduce) dans la version par colonnes.

### 3. Loi d‚ÄôAmdahl et de Gustafson

- Fraction parall√©lisable : `p = 0.9`
- Speedup maximal th√©orique (Amdahl) :  
  **Smax = 10**
- Un nombre de n≈ìuds raisonnable est d‚Äôenviron **6 √† 10**, au-del√† duquel l‚Äôefficacit√© chute fortement.
- En doublant la taille des donn√©es, la loi de **Gustafson** pr√©dit un speedup plus favorable (‚âà 5.74 pour 6 n≈ìuds).

## Remarques

- Tous les r√©sultats pr√©sent√©s ont √©t√© obtenus exp√©rimentalement.
- Les analyses mettent en √©vidence l‚Äôimpact du **choix de la strat√©gie de parall√©lisation** et du **co√ªt des communications**.

---

**Auteur :**  
Yara EL CHAM  
√âl√®ve ing√©nieur ‚Äì ENSTA Paris  
Institut Polytechnique de Paris
